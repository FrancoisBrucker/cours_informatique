{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthodes hiérarchiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://fr.wikipedia.org/wiki/Regroupement_hi%C3%A9rarchique\n",
    "\n",
    "Il fonctionne avec des données décrites par une distance. Il construit des classes emboîtées et peut être repéresenté par une hiérarchie (un arbre).\n",
    "\n",
    "L'intérêt de ces méthodes est :\n",
    "* de permettre une classification sans avoir à choisir un nombre de classe\n",
    "* d'avoir des classes de plus en plus grosse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une hiérarchie est un ensemble de classes $\\mathcal{H}$ tel que pour tous $A, B \\in \\mathcal{H}$ on a : $A \\cap B \\in \\{ A, B, \\phi\\}$ (deux classes sont soit disjointes soit emboîtées).\n",
    "\n",
    "C'est une forme de généralisation d'une partition. C'est également un arbre si on considère l'inclusion : les enfants d'une classe étants les classes strictement plus petite que celle-ci (on appelle cet arbre un *dendregramme*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## algorithme\n",
    "\n",
    "* **Entrée** : \n",
    "    * un ensemble $X$ de $n$ éléments à classer\n",
    "    * une distance $d$ entre les éléments\n",
    "    * une façon de mettre à jour la distance : $f$: $X \\times X \\rightarrow \\mathbb{R}$    \n",
    "* **Sortie** : Un ensemble de classes formant une hiérarchie\n",
    "\n",
    "* **Algorithme** :\n",
    "    * On considère que $\\mathcal{H}$ est l'ensemble des singletons formé avec l'ensmelbe des éléments à classer.\n",
    "    * $\\mathcal{C} = \\mathcal{H}$\n",
    "    * la distance entre 2 singletons est la distance entre les deux éléments.\n",
    "    * répète $n-1$ fois :\n",
    "        * soient $A$ et $B$ deux éléments de $\\mathcal{C}$ ayant une distance minimale\n",
    "        * on ajoute $A \\cup B$ à $\\mathcal{C}$ et on supprime $A$ et $B$ de $C$        \n",
    "        * pour tout $C \\in \\mathcal{C}$, la distance entre $C$ et $A\\cup B$ est $f(C, A\\cup B)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme dépend donc d'une fonction $f$ permettant de mettre à jour la distance. Il en existe de nombreuses, qui vont changer l'arbre solution. sklearn ensupporte 4 :\n",
    "* “ward” : à utiliser pour des données euclidienne : $f(A, B)$ est la perte d'inertie à regrouper $A$ et $B$ $I(A \\cup B) - I(A) - I(B)$\n",
    "* “average” : méthode par défaut. Basée sur des moyennes : $f(A, B) = \\frac{1}{|A| * |B|}\\sum_{x \\in A, y \\in B} d(x, y)$\n",
    "* “complete” : prend la plus grande distance (méthode pssimiste) : $f(A, B) = \\max_{x \\in A, y \\in B} d(x, y)$\n",
    "* “single” : prend la plus petite distance (méthode optimiste) : $f(A, B) = \\min_{x \\in A, y \\in B} d(x, y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "iris = sns.load_dataset('iris').drop(columns=\"species\")\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a toujours 3 espèces que l'on représentera en 3 clouleurs différentes. Les 50 premières sont de l'espèce *setosa*, les 50 suivantes de l'espèce *versicolor* et les 50 dernière de l'espèce *virginica*\n",
    "\n",
    "**Attention** : ces 3 espèces sont des *meta* données : ce sont les botanistes qui ont répartis les iris en espèces, ce n'est pas inhérent aux données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour que nos arbres puissent être visibles, on ne va prendre qu'une partie des données, les 10 premières de chaque espèces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = iris[([True] * 10 + [False] * 40) * 3]\n",
    "\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par défaut, l'algorithme ne calcule que 2 classes (sk-learn est une bibliothèque de machine learning et ils ne savent compter que jusqu'à 2... POur répondre toujours à la question OUI/NON). Nous on veut tout l'arbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris, on utilise ward\n",
    "# par défaut, la distance euclidienne est utilisée.\n",
    "\n",
    "clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=0).fit(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noeuds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque nœud crée a 2 enfants, les nœuds qui ont été agrégés  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clustering.children_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos données initiales sont les plus petits nœuds (ici les nœuds d'index 0 à 29). Puis chaque nœud crée va avoir un numéro plus grand. \n",
    "\n",
    "Le 1er nœud crée (qui est l'agrégation des nœuds 0 et 4) va ainsi avoir l'index 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1er noeud crée a lié les 2 noeuds : \n",
    "clustering.children_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le noeud crée à la 12ème itération a lié les noeud : \n",
    "clustering.children_[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on aggrège à chaque fois 2 classes, le nombre d'itération est égale à 29 (le nombre d'élément moins 1) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clustering.children_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hauteur d'agrégation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La hauteur d'arégation de chaque classe pour chaque itération :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering.distances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hauteur de la première itération : \n",
    "clustering.distances_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hauteur de la 12 itérations itération : \n",
    "clustering.distances_[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La hauteur va souvent avoir une courbe *exponentielle* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.lineplot(x=list(range(len(clustering.distances_))), \n",
    "                y=clustering.distances_, \n",
    "                legend=False,\n",
    "                ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Représentation graphique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour dessiner l'arbre (qu'on appelle dendrogramme), on a besoin des coordonnées de chaque nœud. On peut se restreindre aux coordonnées sur l'axe des abcisse des élémentsde départ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fils = clustering.children_\n",
    "hauteur = clustering.distances_\n",
    "n = len(clustering.labels_)\n",
    "\n",
    "\n",
    "node_position = pandas.DataFrame([(0, 0) for i in range(n)], \n",
    "                             columns=['x', 'y'])\n",
    "\n",
    "node_position \n",
    "\n",
    "pos = [0]\n",
    "def backtracking(noeud):\n",
    "    for x in noeud:\n",
    "        if x < n:\n",
    "            node_position.loc[x , 'x'] = pos[0]\n",
    "            pos[0] += 1\n",
    "        else:\n",
    "            backtracking(fils[x - n])\n",
    "\n",
    "backtracking(fils[-1])\n",
    "\n",
    "for i, (son1, son2) in enumerate(fils):\n",
    "    pos = 0.5 * (node_position.loc[son1]['x'] + node_position.loc[son2]['x'])\n",
    "    node_position = pandas.concat([node_position, pandas.DataFrame([(pos, hauteur[i])], columns=['x', 'y'])], ignore_index=True)\n",
    "    \n",
    "node_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(clustering.labels_)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.scatterplot(x='x', \n",
    "                y='y', \n",
    "                data=node_position,\n",
    "                legend=False,\n",
    "                ax=ax)\n",
    "\n",
    "for i, sons in enumerate(fils):\n",
    "    u = node_position.loc[i + n]    \n",
    "    v1 = node_position.loc[sons[0]]\n",
    "    v2 = node_position.loc[sons[1]]\n",
    "    \n",
    "    l = mlines.Line2D([u['x'], v1['x']] , [u['y'], v1['y']])\n",
    "    ax.add_line(l)\n",
    "    l = mlines.Line2D([u['x'], v2['x']] , [u['y'], v2['y']])\n",
    "    ax.add_line(l)\n",
    "\n",
    "\n",
    "for i, row in node_position.iterrows():\n",
    "    ax.text(row['x'], row['y'], i)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit bien quele 1er nœud crée est d'index 30 et à agrégé les nœuds 0 et 4 à une hauteur de .14\n",
    "\n",
    "Le noeud crée à la 12 itération est d'index 29 + 12 = 41."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut améliorer le dessin en ne légendant que les données de départ. Pour cela, on va créer un dictionnaire de correspondance entre le nœud de l'arbre et son label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée le dictionnaire en itérant sur les lignes du dataframe (`iris.iterrows()`). Cette itération rend à chaque passage un couple `(index, row)` le premier correspondant à l'index (le nom) de la linge et le secon à la ligne proprement dite.\n",
    "\n",
    "Ceci ne suffit pas pour nous, puisqu'il nous faut également lenuméro de la ligne (qui est différent de l'index). Pour cela on utilise [une technique de bouble](https://docs.python.org/fr/3.5/tutorial/datastructures.html#looping-techniques) avec `enumerate`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iris\n",
    "\n",
    "labels = dict()\n",
    "\n",
    "for i, (index, row) in enumerate(iris.iterrows()):\n",
    "    labels[i] = index\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a alors le dessin suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# données : \n",
    "# - clustering : issu de AgglomerativeClustering \n",
    "# - node_position : dataframe contenant la position des différents nœuds du clustering (voir au-dessus pour son calcul)\n",
    "# - labels : le label des nœuds\n",
    "\n",
    "n = len(clustering.labels_)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.scatterplot(x='x', \n",
    "                y='y', \n",
    "                data=node_position,\n",
    "                legend=False,\n",
    "                ax=ax)\n",
    "\n",
    "for i, sons in enumerate(fils):\n",
    "    u = node_position.loc[i + n]    \n",
    "    v1 = node_position.loc[sons[0]]\n",
    "    v2 = node_position.loc[sons[1]]\n",
    "    \n",
    "    l = mlines.Line2D([u['x'], v1['x']] , [u['y'], v1['y']])\n",
    "    ax.add_line(l)\n",
    "    l = mlines.Line2D([u['x'], v2['x']] , [u['y'], v2['y']])\n",
    "    ax.add_line(l)\n",
    "\n",
    "\n",
    "for i, row in node_position.iterrows():\n",
    "    if i in labels:\n",
    "        ax.text(row['x'], row['y'], labels.get(i, i), \n",
    "                horizontalalignment='center',\n",
    "                verticalalignment='top', \n",
    "               rotation=-90)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que les espèces sont bien conservées par les classes (de 0 à 9, de 50 à 59 et de 100 à 19)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAH comme une méthode de partitionnement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise cette méthode d partitionnement plutôt que la méthode des $k$-means si :\n",
    "* on a des formes non ronde de classes à trouver (après une isomap par exemple) :https://scikit-learn.org/stable/modules/clustering.html\n",
    "* nos données sont décrites par une distance non euclidienne\n",
    "\n",
    "**Attention** : on perd la notion d'inertie, il est donc impossible de déterminer *a priori* si une partition est meilleure qu'une autre. Il faut se créer sa propre *fonction objectif* pour déterminer la meilleure partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut utiliser notre méthode hiérarchique pour trouver une partition de de façon différente :\n",
    "- on arrète l'algorithme lorqu'il n'y a plus que $k$ classes (si on veut tout l'arbre on vueut qu'il ne reste plus qu'une seule classe)\n",
    "- on fixe une hauter et on coupe la hiérarchie à cette hauteur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  nombre de classe fixé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn` permet de faire ça grace au paramètre `n_clusters`\n",
    "\n",
    "Si on fixe le nombre de classes à 4, on arête l'algorithme de la CAH lorsqu'il ne reste que 4 classes (ce sera les classes d'index 54, 42, 48 et 55 de notre arbre complet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = AgglomerativeClustering(n_clusters=4).fit(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On retrouve les classes dans l'attribut `labels_` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y en a bien 4. On peut maintenant regarder leurs adéquation aux espèces d'iris : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering.labels_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering.labels_[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering.labels_[20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coupe à une hauter donnée\n",
    "\n",
    "On commence par créer tout l'arbre, puis on regarde les hauteurs d'aggrégation.\n",
    "\n",
    "Une fois la hauteur de coupe déterminée (juste avant la montée exponentielle si elle existe), on ré-exécute la classification avec ce paramètre. Ceci nous donnera les classes conservées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=0).fit(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.lineplot(x=list(range(len(clustering.distances_))), \n",
    "                y=clustering.distances_, \n",
    "                legend=False,\n",
    "                ax=ax)\n",
    "\n",
    "plt.axhline(2, color=\"red\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va couper à 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = AgglomerativeClustering(n_clusters=None,\n",
    "                                    compute_full_tree=True,\n",
    "                                    distance_threshold=2\n",
    "                                   ).fit(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition.labels_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition.labels_[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition.labels_[20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comme méthode d'organisation\n",
    "\n",
    "\n",
    "Permet d'organiser une matrice en éléments similaires. On fait une hiérarchie sur les ligne et le colonne puis on réordonne la matrice avec les hirarchies obtenues. \n",
    "\n",
    "Seaborn le fait tout seul pour nous :\n",
    "https://seaborn.pydata.org/examples/structured_heatmap.html\n",
    "\n",
    "Idéal pour une matrice de corrélation par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toutes les iris\n",
    "\n",
    "Refaisons nos algorithmes avec toutes les iris en tentant de trouver une bonne partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris').drop(columns=\"species\")\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbre complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=0).fit(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fils = clustering.children_\n",
    "hauteur = clustering.distances_\n",
    "n = len(clustering.labels_)\n",
    "\n",
    "\n",
    "node_position = pandas.DataFrame([(0, 0) for i in range(n)], \n",
    "                             columns=['x', 'y'])\n",
    "\n",
    "node_position \n",
    "\n",
    "pos = [0]\n",
    "def backtracking(noeud):\n",
    "    for x in noeud:\n",
    "        if x < n:\n",
    "            node_position.loc[x , 'x'] = pos[0]\n",
    "            pos[0] += 1\n",
    "        else:\n",
    "            backtracking(fils[x - n])\n",
    "\n",
    "backtracking(fils[-1])\n",
    "\n",
    "for i, (son1, son2) in enumerate(fils):\n",
    "    pos = 0.5 * (node_position.loc[son1]['x'] + node_position.loc[son2]['x'])\n",
    "    node_position = pandas.concat([node_position, pandas.DataFrame([(pos, hauteur[i])], columns=['x', 'y'])], ignore_index=True)\n",
    "node_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(clustering.labels_)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.scatterplot(x='x', \n",
    "                y='y', \n",
    "                data=node_position,\n",
    "                legend=False,\n",
    "                ax=ax)\n",
    "\n",
    "for i, sons in enumerate(fils):\n",
    "    u = node_position.loc[i + n]    \n",
    "    v1 = node_position.loc[sons[0]]\n",
    "    v2 = node_position.loc[sons[1]]\n",
    "    \n",
    "    l = mlines.Line2D([u['x'], v1['x']] , [u['y'], v1['y']])\n",
    "    ax.add_line(l)\n",
    "    l = mlines.Line2D([u['x'], v2['x']] , [u['y'], v2['y']])\n",
    "    ax.add_line(l)\n",
    "\n",
    "\n",
    "for i, row in node_position.iterrows():\n",
    "    ax.text(row['x'], row['y'], i)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coupe à hauteur donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=0).fit(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.lineplot(x=list(range(len(clustering.distances_))), \n",
    "                y=clustering.distances_, \n",
    "                legend=False,\n",
    "                ax=ax)\n",
    "\n",
    "plt.axhline(2, color=\"red\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On coupe toujours à une hauteur de 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = AgglomerativeClustering(n_clusters=None,\n",
    "                                    compute_full_tree=True,\n",
    "                                    distance_threshold=2\n",
    "                                   ).fit(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a 9 classes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(partition.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces classes sont très homogènes avec les 3 espèces d'iris. On peut le remarquer en intersectant les classes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(partition.labels_[:50]).intersection(partition.labels_[50:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(partition.labels_[:50]).intersection(partition.labels_[100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(partition.labels_[50:100]).intersection(partition.labels_[100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comptons le nombre d'éléments par classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(partition.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque éspèce :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(partition.labels_[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(partition.labels_[50:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(partition.labels_[100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
