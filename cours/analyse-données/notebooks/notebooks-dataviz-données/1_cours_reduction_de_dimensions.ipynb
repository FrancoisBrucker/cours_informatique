{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Dimensional Scaling (MDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les méthodes de MDS consitent à projeter des données dans un espace de dimension réduite tout en conservant au mieux\n",
    "une distance entre les données.\n",
    "\n",
    "De nombreuses méthodes existent (voir par exemple http://en.wikipedia.org/wiki/Multidimensional_scaling, ou http://scikit-learn.org/stable/_downloads/plot_lle_digits.py) nous n'en présenterons ici que quelques une."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'intérêt de ces méthodes est (au moins) double :\n",
    "* il permet de représenter dansun espace de petite dimenstion des données a priri décrites dansun grand nombre de dimension\n",
    "* il permet d'associer des axes à des données uniqueent décrite par une distance. Ceci permet de faire ensite une ACP dessus pour interpréter les données, faire des régressions, ou utiliser des algorithmes uniquement prévu pour le cas euclidien (comme les $k$-means par exemple)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "current_palette = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris').drop(columns=\"species\")\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que représenter graphiquement ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(iris)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a toujours 3 espèces que l'on représentera en 3 clouleurs différentes. Les 50 premières sont de l'espèce *setosa*, les 50 suivantes de l'espèce *versicolor* et les 50 dernière de l'espèce *virginica*\n",
    "\n",
    "**Attention** : ces 3 espèces sont des *meta* données : ce sont les botanistes qui ont répartis les iris en espèces, ce n'est pas inhérent aux données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthode 1 : les 2 premiers axes de l'ACP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On y reviendra, mais lACP est une méthode qui permet de conserver l'inertie du nuage de points.\n",
    "\n",
    "Prendre les 2 premiers axes correspond à maximiser la projection des points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACP de données non centrée/réduite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA \n",
    "import numpy as np\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "\n",
    "U = np.transpose(pca.components_) # vecteurs propres\n",
    "I = pandas.DataFrame(np.transpose(pca.explained_variance_ratio_), columns=[\"pourcentage\"])  # information véhiculée\n",
    "\n",
    "C = pandas.DataFrame(X @ U, index=X.index) # nouvelles coordonnées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pourcentage d'inertie (l'_information_) conservée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On projette nos données sur les 2 premiers axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = C.iloc[:, [0, 1]]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On représente graphiquement le résultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**bug** : avec les anciennes versions de seaborn, les noms de colonnes doivent être des `str` (sinon la designation d'une colonne comme axe (dans le sns.scatterplot ne fonctionne pas). Si cela vous arrive, renommez les colonnes en str (`data.columns = (str(x) for x in data.columns)`\n",
    "\n",
    "On renomme donc les colonnes par des `str`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "current_palette = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.scatterplot(x=0, \n",
    "                y=1, \n",
    "                data=data,\n",
    "                legend=False,\n",
    "                hue = [0] * 50 + [1] * 50 + [2] * 50,\n",
    "                palette=current_palette[:3],\n",
    "                ax=ax)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut même ajouter le label de cahque donnée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.scatterplot(x=0, \n",
    "                y=1, \n",
    "                data=data,\n",
    "                legend=False,\n",
    "                hue = [0] * 50 + [1] * 50 + [2] * 50,\n",
    "                palette=current_palette[:3],\n",
    "                ax=ax)\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    ax.annotate(str(index), (row[0], row[1]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthode 2 : le hasard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela peut sembler idiot, mais sur des données de grandes dimensions c'est (prouvé) assez efficace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise un module de sklearn https://scikit-learn.org/stable/modules/random_projection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On choisi ici 2 nouveaux axes aléatoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import random_projection\n",
    "\n",
    "rp = random_projection.SparseRandomProjection(n_components=2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On projette nos données dessus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_random = rp.fit_transform(iris)\n",
    "\n",
    "\n",
    "iris_random = pandas.DataFrame(iris_random, index=iris.index)\n",
    "\n",
    "iris_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On représente graphiquement le résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iris_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iris_random\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.scatterplot(x=0, \n",
    "                y=1, \n",
    "                data=data,\n",
    "                legend=False,\n",
    "                hue = [0] * 50 + [1] * 50 + [2] * 50,\n",
    "                palette=current_palette[:3],\n",
    "                ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthode 3 : le MDS classique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos données sont ici décrites par une distance (pas forcément euclidienne) et on veut trouver $k$ axes telle que cette distance corresponde à la distance euclienne de points sur ces $k$ axes. \n",
    "\n",
    "voir : https://fr.wikipedia.org/wiki/Positionnement_multidimensionnel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nos iris sont décritent dans un espace à 4 dimensions. \n",
    "\n",
    "On va commencer par déterminer une distance entre nos iris. Nous allons utiliser la distance euclidienne mais il y en a plein d'autres de possible : \n",
    "\n",
    "https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics\n",
    "\n",
    "voir aussi https://towardsdatascience.com/3-basic-distance-measurement-in-text-mining-5852becff1d7 pour les 3 distances les plus utilisées (la dernière va vous surprendre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance euclidienne entre nos données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import euclidean_distances\n",
    "\n",
    "d = euclidean_distances(iris)\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c'est une liste de liste. Par exemple distance entre l'élément 0 et l'élément 42\n",
    "d[0][42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ou au format numpy\n",
    "\n",
    "d[0, 42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche ensuite 2 dimensions pour les quelles cette distance serait bien conservée\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.manifold.MDS.html#sklearn.manifold.MDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On trouve 2 axes permettant de recréer la distance de façon approchée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mds = manifold.MDS(n_components=2, max_iter=3000,\n",
    "                   dissimilarity=\"precomputed\", n_jobs=1, n_init=5)\n",
    "\n",
    "pos = mds.fit(d).embedding_\n",
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On représente graphiquement le résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.DataFrame(pos)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.scatterplot(x=0, \n",
    "                y=1, \n",
    "                data=data,\n",
    "                legend=False,\n",
    "                hue = [0] * 50 + [1] * 50 + [2] * 50,\n",
    "                palette=current_palette[:3],\n",
    "                ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthode 4 : isomap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On essaie non pas de conserver toutes les distances mais seulement les $k$ plus proches.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.manifold.Isomap.html#sklearn.manifold.Isomap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On trouve 2 axes permettant de recréer la distance des 10 plus proches voisins de façon approchée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mds = manifold.Isomap(n_neighbors=10,\n",
    "                      n_components=2, max_iter=3000,                      \n",
    "                      metric=\"precomputed\")\n",
    "\n",
    "pos = mds.fit(d).embedding_\n",
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On représente graphiquement le résultat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.DataFrame(pos)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.scatterplot(x=0, \n",
    "                y=1, \n",
    "                data=data,\n",
    "                legend=False,\n",
    "                hue = [0] * 50 + [1] * 50 + [2] * 50,\n",
    "                palette=current_palette[:3],\n",
    "                ax=ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
