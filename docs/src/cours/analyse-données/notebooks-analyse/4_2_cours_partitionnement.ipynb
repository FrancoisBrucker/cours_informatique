{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitionnement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va utiliser l'algorithme des $k$-means. Il fonctionne pour des données dérites dans $\\mathbb{R}^m$ (bref des points). Il fonctionne en utilisant des analogies géométrique.\n",
    "\n",
    "Son fonctionnement est décrit là : \n",
    "* https://fr.wikipedia.org/wiki/K-moyennes\n",
    "* https://stanford.edu/~cpiech/cs221/handouts/kmeans.html\n",
    "* https://scikit-learn.org/stable/modules/clustering.html\n",
    "* https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme\n",
    "\n",
    "* **Entrée** : \n",
    "    * un ensemble de $n$ points à classer\n",
    "    * $k$ centres $g_1, \\dots, g_k$ (avec $k << n$)\n",
    "    * un nombre d'itérations $p$\n",
    "    \n",
    "* **Sortie** : $k$ classes\n",
    "\n",
    "* **Algorithme** :\n",
    "    * répète p fois :\n",
    "        * Pour tout $i$ : on associe à la classe $C_i$ tous les points qui sont plus proche de $g_i$ que de tous les autres\n",
    "            centres\n",
    "        * Pour tout $i$ : on associe à $g_i$ le centre de gravité des éléments de $C_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les $k$ premiers centres sont souvent choisis aléatoirement au départ. Ceci n'est pas un problème car les centres sont *attirés* par les ensembles denses de points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme est souvent recommencé plusieurs fois et c'est la *meilleure* solution qui est retenue selon le critère du minimum d'inertie intra-classes :\n",
    "\n",
    "$$\\sum_{i=1}^{k} \\sum_{x \\in C_i} || x - g_i||^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération de données\n",
    "\n",
    "On crée 4 ensembles de données (des [blobs](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html)) pour tester l'algorithme : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=300, centers=4,\n",
    "                       cluster_std=0.60, random_state=0)\n",
    "\n",
    "blobs = pd.DataFrame(X, columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.scatterplot(x='x', \n",
    "                y='y', \n",
    "                data=blobs,\n",
    "                ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation de l'algorithme\n",
    "\n",
    "On utilise l'implémentation faite dans [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plusieurs paramètres possibles, on en utilisera 3 :\n",
    "- `n_clusters` : nombre de classes voulues\n",
    "- `n_init`: nombre de fois où l'on relance l'algorithme, le résultat rendu sera celui avec le minimum d'inertie.\n",
    "- `max_iter` : pour chaque exécution de l'algorithme on s'arrête au bout de 300 itérations s'il n'y a paas eu convergence avant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4,\n",
    "                n_init=10, \n",
    "                max_iter=300).fit(blobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nombre d'itération\n",
    "\n",
    "On a laisser la possibilité de faire 300 itérations avant de s'arrêter s'il n'y a pas eu convergence. Notre algorithme en a fait beaucoup moins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### les centres des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### les classes trouvées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les points sont associés aux centre les plus proches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_kmeans = kmeans.predict(blobs)\n",
    "\n",
    "clusters_kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualité du résultat\n",
    "\n",
    "La qualité de la partition est qualticulé grâce à sont inertie. \n",
    "\n",
    "**Attention** : on ne peut pas connaître l'inertie minimum que l'on peut avoir pour un un jeu de donnée. C'est un problème NP-difficile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va donner une couleur à chaque classe (la variable `colors`) ce qui nous permettra avec seaborn d'affecter un `hue` à chaque élément (sa classe) qui correspondra à la clé d'une couleur de la `palette` (un dictionnaire dont les clés sont des entier et les valeurs une couleur) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#couleurs \n",
    "current_palette = sns.color_palette()\n",
    "colors = {i: current_palette[i] for i in range(len(centers))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(current_palette[:len(centers)]) # https://seaborn.pydata.org/tutorial/color_palettes.html\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.scatterplot(x='x', \n",
    "                y='y', \n",
    "                data=blobs,\n",
    "                hue=clusters_kmeans,\n",
    "                palette=colors,\n",
    "                legend=False,\n",
    "                ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ajoute le centre de chaque classe avec :\n",
    "* la bonne couleur (le numéro de la classe en `hue` et la palette) \n",
    "* une grosse taille (`s=200`)\n",
    "* et un peu transparent (`alpha=0.7`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.scatterplot(x='x', \n",
    "                y='y', \n",
    "                data=blobs,\n",
    "                hue=clusters_kmeans,\n",
    "                palette=colors,\n",
    "                legend=False,\n",
    "                ax=ax)\n",
    "\n",
    "sns.scatterplot(x=centers[:, 0], y=centers[:, 1], \n",
    "                hue=list(range(len(centers))),\n",
    "                palette=colors,\n",
    "                s=200, alpha=0.7,\n",
    "                legend=False,\n",
    "                ax=ax)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence\n",
    "\n",
    "L'algorithme converge vers une solution, au sens où les classes vont s'arrêter de bouger à partir d'un moment. On prouve cela en montrant que l'inertie diminue à chaque itération. Une fois que l'inertie ne diminue plus, le système est stable.\n",
    "\n",
    "**preuve** : \n",
    "* Soient $C_1, \\dots C_k$ les classes avant itération et $C'_1, \\dots C'_k$ les classes après itération. \n",
    "* Soient $g_1, \\dots g_k$ les centres de gravités de $C_1, \\dots C_k$ et $g'_1, \\dots g'_k$ les centres de gravités de $C'_1, \\dots C'_k$.\n",
    "\n",
    "Par construction de l'algorithme on a : $\\sum_{i=1}^{k} \\sum_{x \\in C'_i} || x - g_i||^2 \\leq \\sum_{i=1}^{k} \\sum_{x \\in C_i} || x - g_i||^2$\n",
    "\n",
    "et comme $\\sum_{i=1}^{k} \\sum_{x \\in C'_i} || x - g'_i||^2  \\leq \\sum_{i=1}^{k} \\sum_{x \\in C'_i} || x - g_i||^2$ on a bien que l'inertie baisse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque** : l'algorithmte comverge également si l'on recalcule le centre de gravité à chaque affectation. C'est la version *online* de l'algorithme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention** : L'algorithme converge, mais pas forcément à l'optimum ! C'est pour quoi on le relance plusieurs fois (typiquement 10 fois)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inertie finale pour le k-means précédent\n",
    "\n",
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation\n",
    "\n",
    "Comme on a une mesure de qualité du résultat (l'inertie) et que l'algorithme va très vite (il converge très très rapidment), on peur le lancer de nombreuses fois. \n",
    "\n",
    "C'est une méthode classique lorsque l'on essaie de résoudre des problème de façon approchée et que l'on possède un moyen de comparer les résultats entre eux (ce qui n'est pas toujours le cas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre d'itération avant convergence. C'est très très inférieur au max = 300 \n",
    "\n",
    "kmeans.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condition d'utilisation\n",
    "\n",
    "**Attention** : l'algorithme des $k$-means est très efficace dans son domaine de validité, mais il devient vite inefficace si l'on s'en éloigne.\n",
    "\n",
    "Il faut en connaître les limites pour bien l'utiliser :\n",
    "\n",
    "* nombre de dimensions\n",
    "* forme des classes : rondes (gaussiennes)\n",
    "* nombre de classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombre de dimensions\n",
    "\n",
    "plus il y a de dimensions, plus il existe de minima locaux dans l'inertie (leur nombre augmente potentiellement  exponentiellement avec la dimension), et donc plus il se perd. \n",
    "\n",
    "On effectuera souvent **une réduction de dimension** avant (voir cours suivant)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forme des classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme des $k$-means cherche à trouver des classes **rondes**, il n'est donc pas adapté à la recherche de classe rectangulaires.\n",
    "\n",
    "On va comparer les résultat avec 2 formes rectangulaires de classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rectangles [1, 2] x [1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rectangles = []\n",
    "\n",
    "hauteur = 3 \n",
    "\n",
    "for i in range(150):\n",
    "    x = random.uniform(1, 2)\n",
    "    y = random.uniform(1, hauteur)\n",
    "    \n",
    "    rectangles.append((x, y))\n",
    "\n",
    "for i in range(150):\n",
    "    x = random.uniform(3, 4)\n",
    "    y = random.uniform(1, hauteur)\n",
    "    \n",
    "    rectangles.append((x, y))\n",
    "    \n",
    "rectangles = pd.DataFrame(rectangles, columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.scatterplot(x='x', \n",
    "                y='y', \n",
    "                data=rectangles,\n",
    "                ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2,\n",
    "                n_init=10, \n",
    "                max_iter=300).fit(rectangles)\n",
    "\n",
    "clusters_kmeans = kmeans.predict(rectangles)\n",
    "centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {i: current_palette[i] for i in clusters_kmeans}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.scatterplot(x='x', \n",
    "                y='y', \n",
    "                data=rectangles,\n",
    "                hue=clusters_kmeans,\n",
    "                palette=colors,\n",
    "                legend=False,\n",
    "                ax=ax)\n",
    "\n",
    "sns.scatterplot(x=centers[:, 0], y=centers[:, 1], \n",
    "                hue=list(range(len(centers))),\n",
    "                palette=colors,\n",
    "                s=200, alpha=0.7,\n",
    "                legend=False,\n",
    "                ax=ax)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résulat est celui attendu car les classes rectangulaires s'inscrivent dans 2 disques disjoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {i: current_palette[i] for i in clusters_kmeans}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.scatterplot(x='x', \n",
    "                y='y', \n",
    "                data=rectangles,\n",
    "                hue=clusters_kmeans,\n",
    "                palette=colors,\n",
    "                legend=False,\n",
    "                ax=ax)\n",
    "\n",
    "sns.scatterplot(x=centers[:, 0], y=centers[:, 1], \n",
    "                hue=list(range(len(centers))),\n",
    "                palette=colors,\n",
    "                s=200, alpha=0.7,\n",
    "                legend=False,\n",
    "                ax=ax)\n",
    "\n",
    "for i in range(len(centers)):\n",
    "    x, y = centers[i]\n",
    "    color = colors[i]\n",
    "    ax.add_artist(Circle((x, y), 1.2, \n",
    "                         fill=False, \n",
    "                        edgecolor=color))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rectangles [1, 2] x [1, 10]\n",
    "\n",
    "Lorsque les rectangles grandissent, on ne peut plus vraiment les inscrire dans des disques disjoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rectangles = []\n",
    "\n",
    "hauteur = 10\n",
    "\n",
    "for i in range(150):\n",
    "    x = random.uniform(1, 2)\n",
    "    y = random.uniform(1, hauteur)\n",
    "    \n",
    "    rectangles.append((x, y))\n",
    "\n",
    "for i in range(150):\n",
    "    x = random.uniform(3, 4)\n",
    "    y = random.uniform(1, hauteur)\n",
    "    \n",
    "    rectangles.append((x, y))\n",
    "    \n",
    "rectangles = pd.DataFrame(rectangles, columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessinons les en respectant les dimensions des axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ax.set_xlim(0, 11)\n",
    "ax.set_ylim(0, 11)\n",
    "\n",
    "sns.scatterplot(x='x', \n",
    "                y='y', \n",
    "                data=rectangles,\n",
    "                ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons ce que va produire les $k$-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2,\n",
    "                n_init=10, \n",
    "                max_iter=300).fit(rectangles)\n",
    "\n",
    "clusters_kmeans = kmeans.predict(rectangles)\n",
    "centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {i: current_palette[i] for i in clusters_kmeans}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ax.set_xlim(0, 11)\n",
    "ax.set_ylim(0, 11)\n",
    "\n",
    "\n",
    "sns.scatterplot(x='x', \n",
    "                y='y', \n",
    "                data=rectangles,\n",
    "                hue=clusters_kmeans,\n",
    "                palette=colors,\n",
    "                legend=False,\n",
    "                ax=ax)\n",
    "\n",
    "sns.scatterplot(x=centers[:, 0], y=centers[:, 1], \n",
    "                hue=list(range(len(centers))),\n",
    "                palette=colors,\n",
    "                s=200, alpha=0.7,\n",
    "                legend=False,\n",
    "                ax=ax)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Densité des classes\n",
    "\n",
    "Il faut que les classes soient bien séparées et de densité équivalentes pour que l'algorithme ne se trompe pas. Nous allons utiliser les données de Ruspini pour exhiber le soucis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# données de ruspini\n",
    "\n",
    "ruspini = pd.read_csv(\"ruspini.csv\").drop(columns='Unnamed: 0')\n",
    "\n",
    "ruspini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention** : les $k$-means se font sur toutes les colonnes des données par défaut. C'est pourquoi on a supprimé (avec un drop) la colonne correspondant au label dans le chargement des données pour pas qu'il participe à l'algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ruspini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.scatterplot(x='x', \n",
    "                y='y', \n",
    "                data=data,\n",
    "                legend=False,\n",
    "                ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les deux classes du haut semblent séparées, mais il existe des points qui font la jonction entre les deux. Si un centre initial est un de ces points, il va s'accaparer les 2 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ne fait qu'une seule itération en choisissant les centres de tel façon à ce qu'il n'y en ait qu'un seul avec une grande ordonnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "kmeans = KMeans(n_clusters=4,\n",
    "                n_init=1, \n",
    "                init=np.array(((0, 0), (20, 0), (60, 0), (60, 140))),\n",
    "                max_iter=300).fit(data)\n",
    "\n",
    "clusters_kmeans = kmeans.predict(data)\n",
    "centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_palette = sns.color_palette()\n",
    "colors = {i: current_palette[i] for i in clusters_kmeans}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.scatterplot(x='x', \n",
    "                y='y', \n",
    "                data=data,\n",
    "                hue=clusters_kmeans, palette=colors,\n",
    "                legend=False,\n",
    "                ax=ax)\n",
    "\n",
    "sns.scatterplot(x=centers[:, 0], y=centers[:, 1], \n",
    "                hue=list(range(len(centers))), palette=colors,\n",
    "                s=200, alpha=0.5,\n",
    "                legend=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque** : cela n'arrive quasi pas si les classes sont de même densité de points et que l'on lance plusieurs fois l'algorithme (l'inertie sera plus basse pour la *bonne* solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4,\n",
    "                n_init=10, \n",
    "                max_iter=300).fit(data)\n",
    "\n",
    "clusters_kmeans = kmeans.predict(data)\n",
    "centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_palette = sns.color_palette()\n",
    "colors = {i: current_palette[i] for i in clusters_kmeans}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.scatterplot(x='x', \n",
    "                y='y', \n",
    "                data=data,\n",
    "                hue=clusters_kmeans, palette=colors,\n",
    "                legend=False,\n",
    "                ax=ax)\n",
    "\n",
    "sns.scatterplot(x=centers[:, 0], y=centers[:, 1], \n",
    "                hue=list(range(len(centers))), palette=colors,\n",
    "                s=200, alpha=0.5,\n",
    "                legend=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nombre de classes\n",
    "\n",
    "Un des principal problème des $k$-means est la détermination du nombre de classes lorsqu'on a aucune idée de ce que ça peut être.\n",
    "\n",
    "Une règle courante est d'utiliser la même méthode que pour choisir le nombre d'axes à étudier en acp : on regarde le point d'inflexion de la courbe d'inertie (en anglais on appelle ça la *elbow method*).\n",
    "\n",
    "Pour les $k$-means on effectuera plusieurs passe en augmentant le nombre de classe et on tracera le graphe de l'inertie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertie = []\n",
    "\n",
    "for nb in range(1, 10):\n",
    "    kmeans = KMeans(n_clusters=nb,\n",
    "                    n_init=10, \n",
    "                    max_iter=300).fit(data)\n",
    "    inertie.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.lineplot(x=list(range(1, len(inertie) + 1)), \n",
    "             y=inertie, \n",
    "             legend=False,\n",
    "             ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre de classe optimal est bien 4.\n",
    "\n",
    "Au point d'inflexion, le *coût* d'ajout d'une classe est plus élevé que le gain en inertie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dernière recommendation\n",
    "\n",
    "Il faut que vos données soient interprétables. Même s'il n'y a rien à trouver un algorithme va produire une solution.\n",
    "\n",
    "Vérifier **TOUJOURS** que les résultats de vos algorithmes ont un sens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(300):\n",
    "    x = random.uniform(1, 2)\n",
    "    y = random.uniform(1, hauteur)\n",
    "    \n",
    "    data.append((x, y))\n",
    "\n",
    "data = pd.DataFrame(data, columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.scatterplot(x='x', \n",
    "                y='y', \n",
    "                data=data,\n",
    "                legend=False,\n",
    "                ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a produit un jeu de donnée uniforme. Regardons ce que l'es $k$-means en font."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par chercher le nombre de classes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertie = []\n",
    "\n",
    "for nb in range(1, 10):\n",
    "    kmeans = KMeans(n_clusters=nb,\n",
    "                    n_init=10, \n",
    "                    max_iter=300).fit(data)\n",
    "    inertie.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.lineplot(x=list(range(1, len(inertie) + 1)), \n",
    "             y=inertie, \n",
    "             legend=False,\n",
    "             ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a bien une basse d'inertie. On a l'impression  que 4 est un bon nombre de classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4,\n",
    "                n_init=10, \n",
    "                max_iter=300).fit(data)\n",
    "\n",
    "clusters_kmeans = kmeans.predict(data)\n",
    "centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_palette = sns.color_palette()\n",
    "colors = {i: current_palette[i] for i in clusters_kmeans}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.scatterplot(x='x', \n",
    "                y='y', \n",
    "                data=data,\n",
    "                hue=clusters_kmeans, palette=colors,\n",
    "                legend=False,\n",
    "                ax=ax)\n",
    "\n",
    "sns.scatterplot(x=centers[:, 0], y=centers[:, 1], \n",
    "                hue=list(range(len(centers))), palette=colors,\n",
    "                s=200, alpha=0.5,\n",
    "                legend=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a 4 classes qui ont l'air sur le papier formidables. Mais en les regardans on ne voit qu'elle ne font que découper l'espace en 4. Il n'y a pas de valeur ajoutée aux classes par rapport zux axes originaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
